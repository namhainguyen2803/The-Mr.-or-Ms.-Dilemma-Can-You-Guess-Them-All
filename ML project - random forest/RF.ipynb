{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyo3YWfYd002"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sVeJuqizdMHr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from decision_tree_functions import decision_tree_algorithm, decision_tree_predictions\n",
        "from helper_functions import train_test_split, calculate_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kX1-gAXXdzfA",
        "outputId": "d504025d-3656-47f7-e10a-3f70c8e39551"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full_Name</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ngô Xuân Tùng</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bùi Dương Thảo Vy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lưu Thế Huy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nguyễn Thị Vân</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dương Minh Long</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Full_Name  Gender\n",
              "0      Ngô Xuân Tùng       1\n",
              "1  Bùi Dương Thảo Vy       0\n",
              "2        Lưu Thế Huy       1\n",
              "3     Nguyễn Thị Vân       0\n",
              "4    Dương Minh Long       1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"name_full.csv\")\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8zV34120er-5"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D2vEdSp-evGC"
      },
      "outputs": [],
      "source": [
        "full_data=df['Full_Name']\n",
        "labels = df['Gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mh7Ts3YE3fkk"
      },
      "outputs": [],
      "source": [
        "def lowerize(text):\n",
        "  patterns = {\n",
        "  '[àáảãạăắằẵặẳâầấậẫẩ]': 'a',\n",
        "  '[đ]': 'd',\n",
        "  '[èéẻẽẹêềếểễệ]': 'e',\n",
        "  '[ìíỉĩị]': 'i',\n",
        "  '[òóỏõọôồốổỗộơờớởỡợ]': 'o',\n",
        "  '[ùúủũụưừứửữự]': 'u',\n",
        "  '[ỳýỷỹỵ]': 'y'\n",
        "  }\n",
        "  output = text\n",
        "  for regex, replace in patterns.items():\n",
        "    output = re.sub(regex, replace, output)\n",
        "    # deal with upper case\n",
        "    output = re.sub(regex.upper(), replace.upper(), output)\n",
        "  return output.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n16QNB8nLYxg",
        "outputId": "315cdb4e-2f97-472d-e5d8-a303a183a627"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pham quang tung'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lowerize(\"Phạm Quang Tùng\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SmfxqolkLiHq"
      },
      "outputs": [],
      "source": [
        "class TF_IDF():\n",
        "  def __init__(self, corpus, dictionary=None, max_count=None, min_count=None, normalize_tf=False, smooth=True, normalize_tfidf=None):\n",
        "    self.corpus=corpus\n",
        "    self.max_count=max_count\n",
        "    self.min_count=min_count\n",
        "    self.normalize_tf=normalize_tf\n",
        "    self.smooth=smooth\n",
        "    self.normalize_tfidf=normalize_tfidf\n",
        "    self.dictionary = dictionary if dictionary!=None else self.create_dictionary()\n",
        "    self.num_word=len(self.dictionary)\n",
        "    self.word_to_index = self.map_word_to_index()\n",
        "    self.num_document = len(self.corpus)\n",
        "    self.matrix_word_count = self.create_count_matrix()\n",
        "  #return the word in dictionary given index\n",
        "  def retrieve_word(self, index):\n",
        "    return self.dictionary[index]\n",
        "  def create_dictionary(self):\n",
        "    if self.max_count==None and self.min_count==None:\n",
        "      set_word = set()\n",
        "      for doc in self.corpus:\n",
        "        set_word = set_word.union(set(self.word_extraction(doc.lower())))\n",
        "    else:\n",
        "      set_word = set()\n",
        "      map_word_count = self.map_word_to_count()\n",
        "      for doc in self.corpus:\n",
        "        list_word=self.word_extraction(doc.lower())\n",
        "        for word in list_word:\n",
        "          if self.min_count!=None:\n",
        "            if map_word_count[word] < self.min_count:\n",
        "              continue\n",
        "          if self.max_count!=None:\n",
        "            if map_word_count[word] > self.max_count:\n",
        "              continue\n",
        "          set_word.add(word)\n",
        "    return sorted(list(set_word))\n",
        "  def retrieve_index(self, word):\n",
        "    return self.word_to_index[word.lower()]\n",
        "  \n",
        "  def word_extraction(self, document):\n",
        "    split_word=document.split()\n",
        "    return split_word\n",
        "\n",
        "  def map_word_to_count(self):\n",
        "    dict_word_count = dict()\n",
        "    for i in range(len(self.corpus)):\n",
        "      list_word = self.word_extraction(self.corpus[i].lower())\n",
        "      for j in range(len(list_word)):\n",
        "        dict_word_count[list_word[j]] = dict_word_count.get(list_word[j],0)+1\n",
        "    return dict_word_count\n",
        "  \n",
        "  def map_word_to_index(self):\n",
        "    dict_encode=dict()\n",
        "    for i in range(len(self.dictionary)):\n",
        "      dict_encode[self.dictionary[i]]=i\n",
        "    return dict_encode\n",
        "  \n",
        "  def create_count_matrix(self):\n",
        "    mat = np.zeros((self.num_document, self.num_word))\n",
        "    for i in range(len(self.corpus)):\n",
        "      document = self.corpus[i].lower()\n",
        "      list_word = self.word_extraction(document)\n",
        "      for j in range(len(list_word)):\n",
        "        ind = self.retrieve_index(list_word[j])\n",
        "        mat[i, ind]+=1\n",
        "    return mat\n",
        "\n",
        "  def compute_tf(self):\n",
        "    length_name = np.sum(self.matrix_word_count, axis=1)\n",
        "    if self.normalize_tf==True:\n",
        "      return self.matrix_word_count/np.reshape(length_name, (-1,1))\n",
        "    else:\n",
        "      return self.matrix_word_count\n",
        "  \n",
        "  def compute_idf(self):\n",
        "    tmp = np.copy(self.matrix_word_count)\n",
        "    tmp[tmp!=0]=1\n",
        "    num_doc_having_word = np.sum(tmp, axis=0)\n",
        "    if self.smooth == True:\n",
        "      num_doc_having_word = np.log((self.num_document+1) / (num_doc_having_word+1)) + 1\n",
        "    else:\n",
        "      num_doc_having_word = np.log(self.num_document / num_doc_having_word) + 1\n",
        "    \n",
        "    return np.reshape(num_doc_having_word, (1, self.num_word))\n",
        "  def compute_tf_idf(self):\n",
        "    tf = self.compute_tf()\n",
        "    idf = self.compute_idf()\n",
        "    tfidf = tf * idf\n",
        "    if self.normalize_tfidf==None:\n",
        "      return tfidf\n",
        "    elif self.normalize_tfidf == \"l2\":\n",
        "      sum_squares = np.reshape(np.diag(tfidf.dot(tfidf)), (1, -1))\n",
        "      return tfidf / sum_squares\n",
        "    elif self.normalize_tfidf == \"l1\":\n",
        "      sum_row = np.reshape(np.sum(tfidf, axis=1), (1, -1))\n",
        "      return tfidf / sum_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N8PGlbexQrW",
        "outputId": "787fb8fa-bfd5-4b35-c575-712c445e458c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ba', 'doan', 'hai', 'nam', 'nguyen', 'pham', 'quang', 'the', 'thiem', 'tung', 'vinh']\n",
            "[[0.         0.         1.91629073 1.91629073 1.51082562 0.\n",
            "  0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         1.91629073\n",
            "  1.91629073 0.         0.         1.91629073 0.        ]\n",
            " [0.         1.91629073 0.         0.         0.         0.\n",
            "  0.         1.91629073 0.         0.         1.91629073]\n",
            " [1.91629073 0.         0.         0.         1.51082562 0.\n",
            "  0.         0.         1.91629073 0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "list_name = [\"nguyen nam hai\", \"pham quang tung\", \"doan the vinh\", \"nguyen ba thiem\"]\n",
        "test_TF_IDF = TF_IDF(list_name)\n",
        "print(test_TF_IDF.dictionary)\n",
        "print(test_TF_IDF.compute_tf_idf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6bEuR1QyDvQ",
        "outputId": "d6f64934-cba3-4072-d598-4d98fc27037e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26851\n"
          ]
        }
      ],
      "source": [
        "list_of_names=full_data.tolist()\n",
        "list_of_labels = labels.to_numpy()\n",
        "print(len(full_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5sd9nha5Kog",
        "outputId": "7f9206ee-02ea-4710-ceb1-3ec03e6da136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         0    1    2    3    4    5    6    7    8    9  ...  1534  1535  \\\n",
            "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
            "26846  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "26847  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "26848  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "26849  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "26850  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
            "\n",
            "       1536  1537  1538  1539  1540  1541  1542  1543  \n",
            "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
            "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
            "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
            "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
            "26846   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "26847   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
            "26848   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "26849   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "26850   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[26851 rows x 1544 columns]\n"
          ]
        }
      ],
      "source": [
        "TF_IDF_full_data = TF_IDF(list_of_names)\n",
        "onehot_data = np.array(TF_IDF_full_data.matrix_word_count)\n",
        "#svd = TruncatedSVD(n_components=500)\n",
        "#normalizer = Normalizer(copy=False)\n",
        "#X_normalized = normalizer.fit_transform(tfidf_data)\n",
        "#X_svd = svd.fit_transform(X_normalized)\n",
        "onehot_data[onehot_data != 0] = 1\n",
        "onehot_data = np.append(onehot_data, list_of_labels.reshape(-1,1), axis=1)\n",
        "onehot_data_df = pd.DataFrame(onehot_data, columns = [str(i) for i in range(onehot_data.shape[1])])\n",
        "print(onehot_data_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OCOyZfnbLmSr"
      },
      "source": [
        "Test the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx-dIgfFN3Ac",
        "outputId": "cdc52267-9b20-4edd-ce7b-f204008b914a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.indexes.base.Index'>\n"
          ]
        }
      ],
      "source": [
        "#random.seed(42)\n",
        "train_df, test_df = train_test_split(onehot_data_df, 0.2)\n",
        "print(type(train_df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXS952hqbSoD",
        "outputId": "ac01e7a7-945f-4a5c-e5a9-8a21dd0b07ac"
      },
      "outputs": [],
      "source": [
        "def bootstrapping(train_df, n_bootstrap):\n",
        "    bootstrap_indices = np.random.randint(low=0, high=len(train_df), size=n_bootstrap)\n",
        "    df_bootstrapped = train_df.iloc[bootstrap_indices]\n",
        "    \n",
        "    return df_bootstrapped\n",
        "\n",
        "def random_forest_algorithm(train_df, n_trees, n_bootstrap, n_features, dt_max_depth):\n",
        "    forest = []\n",
        "    for i in range(n_trees):\n",
        "        df_bootstrapped = bootstrapping(train_df, n_bootstrap)\n",
        "        tree = decision_tree_algorithm(df_bootstrapped, max_depth=dt_max_depth, random_subspace=n_features)\n",
        "        forest.append(tree)\n",
        "    \n",
        "    return forest\n",
        "\n",
        "def random_forest_predictions(test_df, forest):\n",
        "    df_predictions = {}\n",
        "    for i in range(len(forest)):\n",
        "        if (type(forest[i]) is dict):\n",
        "            column_name = \"tree_{}\".format(i)\n",
        "            predictions = decision_tree_predictions(test_df, tree=forest[i])\n",
        "            df_predictions[column_name] = predictions\n",
        "\n",
        "    df_predictions = pd.DataFrame(df_predictions)\n",
        "    random_forest_predictions = df_predictions.mode(axis=1)[0]\n",
        "    \n",
        "    return random_forest_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'1092 = 1.0': [{'1280 = 1.0': [{'1145 = 1.0': [0.0, 1.0]}, {'1047 = 1.0': [0.0, {'461 = 1.0': [0.0, 1.0]}]}]}, {'310 = 1.0': [0.0, {'1145 = 1.0': [0.0, {'711 = 1.0': [0.0, {'1426 = 1.0': [0.0, 1.0]}]}]}]}]}\n"
          ]
        }
      ],
      "source": [
        "print(decision_tree_algorithm(train_df, counter=0, min_samples=2, max_depth=5, random_subspace=200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xvxqmdhHORly"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'298 = 1.0': [{'756 = 1.0': [0.0, {'1531 = 1.0': [1.0, {'664 = 1.0': [1.0, {'461 = 1.0': [0.0, 1.0]}]}]}]}, {'1379 = 1.0': [{'365 = 1.0': [1.0, {'1456 = 1.0': [1.0, {'1531 = 1.0': [1.0, {'1294 = 1.0': [0.0, 1.0]}]}]}]}, {'1111 = 1.0': [0.0, {'607 = 1.0': [0.0, {'644 = 1.0': [1.0, {'1130 = 1.0': [0.0, {'1117 = 1.0': [0.0, {'925 = 1.0': [0.0, {'467 = 1.0': [0.0, 1.0]}]}]}]}]}]}]}]}]}\n",
            "Accuracy = 0.6575418994413408\n"
          ]
        }
      ],
      "source": [
        "forest = random_forest_algorithm(train_df, n_trees=10, n_bootstrap=1000, n_features=50, dt_max_depth=10)\n",
        "predictions = random_forest_predictions(test_df, forest)\n",
        "accuracy = calculate_accuracy(predictions, test_df.iloc[:,-1])\n",
        "print(forest[0])\n",
        "print(\"Accuracy = {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUx2aTAGuMQ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "RF = RandomForestClassifier(max_depth = 1, random_state=0)\n",
        "DT = DecisionTreeClassifier()\n",
        "#_train, X_test, y_train, y_test = train_test_split(TF_IDF_full_data.one, df.iloc[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "a9pjDOLOuoD6",
        "outputId": "628e1ee6-31bc-4bf8-b284-43f1caa05e89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=1, random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=1, random_state=0)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RF.fit(train_data[:,:-1],train_data[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WML0KNIFurlv",
        "outputId": "4ffd2fde-39b8-4eeb-9438-0abedc214211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5370, 754)\n",
            "(21481, 1409)\n"
          ]
        }
      ],
      "source": [
        "#clf.score(X_test, test_label)\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAiJYldZEWdv",
        "outputId": "3b9760c4-c38b-404e-c229-94d48b4210c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5772811918063314"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RF.score(test_data[:,:-1], test_data[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWPTYU1yb9Ez"
      },
      "outputs": [],
      "source": [
        "test = test_data[:,-1]\n",
        "\n",
        "for i in test:\n",
        "  if i == 1:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0WiIqZSMSOD",
        "outputId": "140735f9-b08b-4288-a583-e02d2039b28a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9365410397735736"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DT.fit(X_train, y_train)\n",
        "DT.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKOEdFX6MaWC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
